# MasterOrchestrator V3 - å¹¶è¡Œæ‰§è¡Œç³»ç»Ÿ

## æ¦‚è¿°

MasterOrchestrator V3 æä¾›äº†æ™ºèƒ½å¹¶è¡Œæ‰§è¡Œèƒ½åŠ›ï¼Œå¯ä»¥è‡ªåŠ¨è¯†åˆ«ç‹¬ç«‹ä»»åŠ¡å¹¶å¹¶è¡Œæ‰§è¡Œï¼Œæ˜¾è‘—æå‡æ‰§è¡Œæ•ˆç‡ã€‚

**æ ¸å¿ƒç‰¹æ€§**ï¼š
- âš¡ **æ™ºèƒ½ä¾èµ–åˆ†æ**ï¼šè‡ªåŠ¨è¯†åˆ«ä»»åŠ¡ä¾èµ–å…³ç³»
- ğŸ”€ **åˆ†å±‚å¹¶è¡Œæ‰§è¡Œ**ï¼šæŒ‰ä¾èµ–å±‚çº§ç»„ç»‡å¹¶è¡Œä»»åŠ¡
- ğŸ” **å¾ªç¯ä¾èµ–æ£€æµ‹**ï¼šå¯åŠ¨æ—¶æ£€æµ‹å¹¶æŠ¥å‘Šå¾ªç¯ä¾èµ–
- â±ï¸ **è¶…æ—¶æ§åˆ¶**ï¼šç‹¬ç«‹çš„ä»»åŠ¡çº§è¶…æ—¶ç®¡ç†
- ğŸ›¡ï¸ **é”™è¯¯éš”ç¦»**ï¼šå•ä¸ªä»»åŠ¡å¤±è´¥ä¸å½±å“å…¶ä»–ä»»åŠ¡
- ğŸ“Š **è¯¦ç»†ç»“æœæ”¶é›†**ï¼šç»Ÿè®¡æˆåŠŸç‡ã€è€—æ—¶ç­‰æŒ‡æ ‡

---

## å¿«é€Ÿå¼€å§‹

### 1. å¯ç”¨å¹¶è¡Œæ‰§è¡Œ

```python
from orchestrator import MasterOrchestrator

# å¯ç”¨è‡ªåŠ¨å‘ç°å’Œå¹¶è¡Œæ‰§è¡Œ
orch = MasterOrchestrator(
    auto_discover=True,        # å¿…é¡»å¯ç”¨è‡ªåŠ¨å‘ç°
    enable_parallel=True,      # å¯ç”¨å¹¶è¡Œæ‰§è¡Œ
    max_parallel_workers=3,    # æœ€å¤§å¹¶è¡Œæ•°
    parallel_timeout=120       # å•ä»»åŠ¡è¶…æ—¶ï¼ˆç§’ï¼‰
)

# æ‰¹é‡å¤„ç†è¯·æ±‚
requests = [
    "æŸ¥çœ‹ git çŠ¶æ€",
    "åˆ†æä»£ç è´¨é‡",
    "ç”Ÿæˆ API æ–‡æ¡£"
]

result = orch.process_batch(requests, enable_parallel=True, verbose=True)

# æŸ¥çœ‹ç»“æœ
print(f"æ€»ä»»åŠ¡: {result.total_tasks}")
print(f"æˆåŠŸ: {result.successful}")
print(f"å¤±è´¥: {result.failed}")
print(f"æˆåŠŸç‡: {result.success_rate:.1%}")
print(f"æ€»è€—æ—¶: {result.total_duration_seconds:.2f}s")
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
[ä»»åŠ¡åˆ›å»º] æŸ¥çœ‹ git çŠ¶æ€ â†’ command:default
[ä»»åŠ¡åˆ›å»º] åˆ†æä»£ç è´¨é‡ â†’ skill:code-analyzer
[ä»»åŠ¡åˆ›å»º] ç”Ÿæˆ API æ–‡æ¡£ â†’ prompt:api-doc

[å¹¶è¡Œæ‰§è¡Œ] 3 ä¸ªä»»åŠ¡ï¼Œæœ€å¤š 3 ä¸ªå¹¶è¡Œ...

æ€»ä»»åŠ¡: 3
æˆåŠŸ: 3
å¤±è´¥: 0
æˆåŠŸç‡: 100.0%
æ€»è€—æ—¶: 5.23s
```

---

## å¹¶è¡Œæ‰§è¡Œæ¨¡å¼

### æ¨¡å¼ 1: æ‰¹é‡å¹¶è¡Œå¤„ç†

**é€‚ç”¨åœºæ™¯**ï¼šå¤šä¸ªç‹¬ç«‹ä»»åŠ¡éœ€è¦å¹¶å‘æ‰§è¡Œ

```python
orch = MasterOrchestrator(
    auto_discover=True,
    enable_parallel=True,
    max_parallel_workers=5
)

# å¤šä¸ªç‹¬ç«‹çš„ä»£ç åˆ†æä»»åŠ¡
files_to_analyze = [
    "åˆ†æ src/main.py ä»£ç è´¨é‡",
    "åˆ†æ src/utils.py ä»£ç è´¨é‡",
    "åˆ†æ src/models.py ä»£ç è´¨é‡",
    "åˆ†æ src/views.py ä»£ç è´¨é‡",
    "åˆ†æ src/tests.py ä»£ç è´¨é‡"
]

# å¹¶è¡Œæ‰§è¡Œï¼ˆæœ€å¤š5ä¸ªåŒæ—¶ï¼‰
result = orch.process_batch(files_to_analyze, enable_parallel=True)

# 5ä¸ªä»»åŠ¡å¹¶è¡Œ vs ä¸²è¡Œï¼š
# å¹¶è¡Œ: ~12s (å‡è®¾æ¯ä¸ªä»»åŠ¡10sï¼Œ5ä¸ªå¹¶è¡Œæ‰§è¡Œ)
# ä¸²è¡Œ: ~50s (5ä¸ªä»»åŠ¡ä¾æ¬¡æ‰§è¡Œ)
# åŠ é€Ÿæ¯”: 4.2x
```

### æ¨¡å¼ 2: DevWorkflow å¹¶è¡Œå·¥ä½œæµ

**é€‚ç”¨åœºæ™¯**ï¼šå¤šé˜¶æ®µå¼€å‘æµç¨‹ï¼Œéƒ¨åˆ†é˜¶æ®µå¯å¹¶è¡Œ

```python
from orchestrator.skills.dev_workflow import DevWorkflowAgent

# å¯ç”¨å¹¶è¡Œå·¥ä½œæµ
agent = DevWorkflowAgent(
    parse_events=True,
    timeout=600,
    enable_parallel=True,    # å¯ç”¨å¹¶è¡Œ
    max_workers=2            # åŒæ—¶æ‰§è¡Œ2ä¸ªé˜¶æ®µ
)

result = agent.run("åˆ›å»ºåœ¨çº¿è¯¾ç¨‹å¹³å°", verbose=True)

# æ‰§è¡Œå±‚çº§ï¼š
# Level 0: [REQUIREMENTS]                    å•ç‹¬æ‰§è¡Œ (~15s)
# Level 1: [FEATURE_DESIGN, UX_DESIGN]       å¹¶è¡Œæ‰§è¡Œ (~15s, åŸæœ¬éœ€è¦30s)
# Level 2: [DEV_PLAN]                        å•ç‹¬æ‰§è¡Œ (~10s)
# Level 3: [IMPLEMENTATION]                  å•ç‹¬æ‰§è¡Œ (~20s)
#
# æ€»è€—æ—¶: ~60s (ä¸²è¡Œéœ€è¦~90s, èŠ‚çœ33%)
```

---

## ä¾èµ–åˆ†æ

### è‡ªåŠ¨ä¾èµ–è§£æ

ç³»ç»Ÿä¼šè‡ªåŠ¨åˆ†æä»»åŠ¡é—´çš„ä¾èµ–å…³ç³»ï¼š

```python
from orchestrator.core.dependency_analyzer import DependencyAnalyzer, Task

# åˆ›å»ºä»»åŠ¡
tasks = [
    Task(namespace="command:git-status", request="æŸ¥çœ‹çŠ¶æ€", dependencies=[]),
    Task(namespace="skill:code-review", request="ä»£ç å®¡æŸ¥", dependencies=["command:git-diff"]),
    Task(namespace="skill:test-gen", request="ç”Ÿæˆæµ‹è¯•", dependencies=["skill:code-review"])
]

# åˆ†æä¾èµ–
analyzer = DependencyAnalyzer(registry=None)
groups = analyzer.group_parallel_tasks(tasks)

# ç»“æœåˆ†å±‚ï¼š
# Level 0: [command:git-status]              ç‹¬ç«‹æ‰§è¡Œ
# Level 1: [command:git-diff]                ä¾èµ– Level 0
# Level 2: [skill:code-review]               ä¾èµ– Level 1
# Level 3: [skill:test-gen]                  ä¾èµ– Level 2
```

### ä¾èµ–å›¾å¯è§†åŒ–

```python
# æ„å»ºä¾èµ–å›¾
graph = analyzer.build_task_graph(tasks)

# è¾“å‡ºä¾èµ–å…³ç³»
for task_ns, deps in graph.items():
    if deps:
        print(f"{task_ns} ä¾èµ–äº:")
        for dep in deps:
            print(f"  - {dep}")
    else:
        print(f"{task_ns} (æ— ä¾èµ–)")
```

**è¾“å‡º**ï¼š
```
command:git-status (æ— ä¾èµ–)
skill:code-review ä¾èµ–äº:
  - command:git-diff
skill:test-gen ä¾èµ–äº:
  - skill:code-review
```

---

## æ‹“æ‰‘æ’åº

### Kahn ç®—æ³•åˆ†å±‚

ç³»ç»Ÿä½¿ç”¨ Kahn ç®—æ³•å¯¹ä»»åŠ¡è¿›è¡Œæ‹“æ‰‘æ’åºå¹¶åˆ†å±‚ï¼š

```python
# ä¾èµ–å›¾
graph = {
    "A": set(),          # æ— ä¾èµ–
    "B": {"A"},          # ä¾èµ– A
    "C": {"A"},          # ä¾èµ– Aï¼ˆå¯ä¸ B å¹¶è¡Œï¼‰
    "D": {"B", "C"},     # ä¾èµ– B å’Œ C
}

# æ‹“æ‰‘æ’åº
levels = analyzer.topological_sort(graph)

# ç»“æœï¼š
# [["A"], ["B", "C"], ["D"]]
#   â†‘      â†‘           â†‘
#  å±‚0    å±‚1         å±‚2
#       (Bå’ŒCå¹¶è¡Œ)
```

### å¹¶è¡Œç»„ç”Ÿæˆ

```python
from orchestrator.core.dependency_analyzer import ParallelGroup

# åˆ†ç»„å¹¶è¡Œä»»åŠ¡
groups = analyzer.group_parallel_tasks(tasks)

for group in groups:
    print(f"Level {group.level}: {len(group.tasks)} ä¸ªä»»åŠ¡")
    if len(group.tasks) > 1:
        print(f"  [å¹¶è¡Œ] {[t.namespace for t in group.tasks]}")
    else:
        print(f"  [ä¸²è¡Œ] {group.tasks[0].namespace}")
```

**è¾“å‡º**ï¼š
```
Level 0: 1 ä¸ªä»»åŠ¡
  [ä¸²è¡Œ] command:git-status

Level 1: 2 ä¸ªä»»åŠ¡
  [å¹¶è¡Œ] ['skill:feature-design', 'skill:ux-design']

Level 2: 1 ä¸ªä»»åŠ¡
  [ä¸²è¡Œ] skill:dev-plan
```

---

## å¹¶è¡Œè°ƒåº¦å™¨

### ThreadPoolExecutor ç®¡ç†

```python
from orchestrator.core.parallel_scheduler import ParallelScheduler
from orchestrator.core.executor_factory import ExecutorFactory

# åˆ›å»ºè°ƒåº¦å™¨
scheduler = ParallelScheduler(
    factory=executor_factory,
    max_workers=3,           # æœ€å¤š3ä¸ªå¹¶è¡Œçº¿ç¨‹
    timeout_per_task=120,    # å•ä»»åŠ¡è¶…æ—¶120ç§’
    fail_fast=False          # ä¸å¿«é€Ÿå¤±è´¥
)

# æ‰§è¡Œå¹¶è¡Œç»„
result = scheduler.execute_parallel_groups(groups)

# ç»“æœ
print(f"æ€»ä»»åŠ¡: {result.total_tasks}")
print(f"æˆåŠŸ: {result.successful}")
print(f"å¤±è´¥: {result.failed}")
print(f"æ€»è€—æ—¶: {result.total_duration_seconds:.2f}s")
```

### åˆ†å±‚æ‰§è¡Œæµç¨‹

```
Level 0: [Task A]
    â†“ æ‰§è¡Œå®Œæˆ
Level 1: [Task B, Task C]  â† ThreadPoolExecutor(max_workers=2)
    â†“ ä¸¤ä¸ªä»»åŠ¡å¹¶è¡Œæ‰§è¡Œ
Level 2: [Task D]
    â†“ æ‰§è¡Œå®Œæˆ
å®Œæˆ
```

### é”™è¯¯éš”ç¦»

```python
# é”™è¯¯éš”ç¦»ï¼šTask B å¤±è´¥ä¸å½±å“ Task C

# Level 1 æ‰§è¡Œ:
with ThreadPoolExecutor(max_workers=2) as executor:
    future_B = executor.submit(execute_task, task_B)
    future_C = executor.submit(execute_task, task_C)

    # Task B å¤±è´¥ï¼ŒTask C ç»§ç»­æ‰§è¡Œ
    try:
        result_B = future_B.result(timeout=120)
    except Exception as e:
        print(f"Task B å¤±è´¥: {e}")
        # è®°å½•å¤±è´¥ï¼Œç»§ç»­

    result_C = future_C.result(timeout=120)  # Task C æ­£å¸¸å®Œæˆ
```

---

## é…ç½®å¹¶è¡Œæ‰§è¡Œ

### å…¨å±€é…ç½®

åœ¨ `orchestrator.yaml` ä¸­é…ç½®ï¼š

```yaml
version: "3.0"

# å¹¶è¡Œæ‰§è¡Œé…ç½®
parallel:
  enabled: true              # å…¨å±€å¯ç”¨å¹¶è¡Œ
  max_workers: 3             # æœ€å¤§å¹¶è¡Œçº¿ç¨‹æ•°
  timeout_per_task: 120      # å•ä»»åŠ¡è¶…æ—¶ï¼ˆç§’ï¼‰
  allowed_modes:             # å…è®¸å¹¶è¡Œçš„æ¨¡å¼
    - command
    - backend
  sequential_modes:          # å¿…é¡»ä¸²è¡Œçš„æ¨¡å¼
    - skill
```

### è¿è¡Œæ—¶è¦†ç›–

```python
# åˆå§‹åŒ–æ—¶ç¦ç”¨
orch = MasterOrchestrator(enable_parallel=False)

# è¿è¡Œæ—¶å¯ç”¨
result = orch.process_batch(
    requests,
    enable_parallel=True,  # è¦†ç›–åˆå§‹åŒ–é…ç½®
    verbose=True
)
```

### Per-Resource é…ç½®

```yaml
skills:
  manual:
    - name: heavy-task
      path: ./skills/heavy-task.yaml
      priority: 100
      # è¯¥ Skill æ€»æ˜¯ä¸²è¡Œæ‰§è¡Œ
      parallel: false
```

---

## æ€§èƒ½ä¼˜åŒ–

### æœ€ä½³å¹¶è¡Œæ•°

æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©åˆé€‚çš„ `max_workers`ï¼š

| ä»»åŠ¡ç±»å‹ | æ¨è max_workers | åŸå›  |
|---------|-----------------|------|
| CPU å¯†é›† | CPU æ ¸å¿ƒæ•° | é¿å…è¿‡åº¦ç«äº‰ |
| IO å¯†é›† | CPU æ ¸å¿ƒæ•° Ã— 2-4 | IO ç­‰å¾…æ—¶å¯å¤„ç†æ›´å¤šä»»åŠ¡ |
| API è°ƒç”¨ | 3-5 | é¿å…è§¦å‘é€Ÿç‡é™åˆ¶ |
| æ··åˆä»»åŠ¡ | CPU æ ¸å¿ƒæ•° Ã— 2 | å¹³è¡¡ CPU å’Œ IO |

**ç¤ºä¾‹**ï¼š
```python
import os

# CPU å¯†é›†ä»»åŠ¡
max_workers = os.cpu_count()  # å¦‚ 8 æ ¸ â†’ 8 workers

# IO å¯†é›†ä»»åŠ¡ï¼ˆAPI è°ƒç”¨ï¼‰
max_workers = min(os.cpu_count() * 2, 10)  # 8 æ ¸ â†’ 10 workers (é™åˆ¶ä¸Šé™)
```

### è¶…æ—¶é…ç½®

```python
# æ ¹æ®ä»»åŠ¡ç±»å‹è®¾ç½®è¶…æ—¶
scheduler = ParallelScheduler(
    factory=factory,
    max_workers=3,
    timeout_per_task=60,     # è½»é‡çº§ä»»åŠ¡ï¼š60s
    # timeout_per_task=300,  # é‡é‡çº§ä»»åŠ¡ï¼š300s
)
```

### æ‰¹æ¬¡å¤§å°

```python
# å¤§é‡ä»»åŠ¡æ—¶åˆ†æ‰¹å¤„ç†
def process_in_batches(requests, batch_size=10):
    results = []
    for i in range(0, len(requests), batch_size):
        batch = requests[i:i+batch_size]
        result = orch.process_batch(batch, enable_parallel=True)
        results.append(result)
    return results

# 100 ä¸ªä»»åŠ¡ï¼Œæ¯æ‰¹ 10 ä¸ª
all_results = process_in_batches(requests, batch_size=10)
```

---

## å¾ªç¯ä¾èµ–æ£€æµ‹

### è‡ªåŠ¨æ£€æµ‹

ç³»ç»Ÿä¼šåœ¨ä»»åŠ¡æ‰§è¡Œå‰æ£€æµ‹å¾ªç¯ä¾èµ–ï¼š

```python
# æ£€æµ‹å¾ªç¯ä¾èµ–
cycles = analyzer.detect_cycles(dependency_graph)

if cycles:
    print(f"æ£€æµ‹åˆ° {len(cycles)} ä¸ªå¾ªç¯ä¾èµ–:")
    for cycle in cycles:
        print(f"  {' â†’ '.join(cycle)}")
    raise CyclicDependencyError("å­˜åœ¨å¾ªç¯ä¾èµ–")
```

**ç¤ºä¾‹**ï¼š
```
æ£€æµ‹åˆ° 1 ä¸ªå¾ªç¯ä¾èµ–:
  skill:A â†’ skill:B â†’ skill:C â†’ skill:A
```

### è§£å†³å¾ªç¯ä¾èµ–

**é”™è¯¯çš„ä¾èµ–**ï¼š
```yaml
# skill-a.yaml
dependencies: ["skill:skill-b"]

# skill-b.yaml
dependencies: ["skill:skill-c"]

# skill-c.yaml
dependencies: ["skill:skill-a"]  # â† å½¢æˆå¾ªç¯
```

**æ­£ç¡®çš„é‡æ„**ï¼š
```yaml
# å¼•å…¥å…±äº« Skill
# skill-common.yaml (æ— ä¾èµ–)

# skill-a.yaml
dependencies: ["skill:skill-common"]

# skill-b.yaml
dependencies: ["skill:skill-common"]

# skill-c.yaml
dependencies: ["skill:skill-common"]
```

---

## ç»“æœæ”¶é›†

### BatchResult ç»“æ„

```python
@dataclass
class BatchResult:
    total_tasks: int              # æ€»ä»»åŠ¡æ•°
    successful: int               # æˆåŠŸæ•°
    failed: int                   # å¤±è´¥æ•°
    total_duration_seconds: float # æ€»è€—æ—¶
    task_results: List[TaskResult]# è¯¦ç»†ç»“æœ
    metadata: Dict[str, Any]      # å…ƒæ•°æ®

    @property
    def success_rate(self) -> float:
        """æˆåŠŸç‡ (0.0-1.0)"""
        return self.successful / self.total_tasks if self.total_tasks > 0 else 0.0
```

### TaskResult ç»“æ„

```python
@dataclass
class TaskResult:
    namespace: str                # èµ„æºå‘½åç©ºé—´
    success: bool                 # æ˜¯å¦æˆåŠŸ
    output: Any                   # è¾“å‡ºç»“æœ
    error: Optional[str]          # é”™è¯¯ä¿¡æ¯
    duration_seconds: float       # è€—æ—¶
    executed_at: datetime         # æ‰§è¡Œæ—¶é—´
    metadata: Dict[str, Any]      # å…ƒæ•°æ®
```

### ç»“æœåˆ†æ

```python
result = orch.process_batch(requests, enable_parallel=True)

# ç»Ÿè®¡ä¿¡æ¯
print(f"æˆåŠŸç‡: {result.success_rate:.1%}")
print(f"å¹³å‡è€—æ—¶: {result.total_duration_seconds / result.total_tasks:.2f}s")

# æŸ¥çœ‹å¤±è´¥ä»»åŠ¡
failed_tasks = [r for r in result.task_results if not r.success]
for task in failed_tasks:
    print(f"å¤±è´¥: {task.namespace}")
    print(f"  é”™è¯¯: {task.error}")

# æŸ¥çœ‹æœ€æ…¢ä»»åŠ¡
sorted_tasks = sorted(result.task_results, key=lambda x: x.duration_seconds, reverse=True)
print(f"æœ€æ…¢ä»»åŠ¡: {sorted_tasks[0].namespace} ({sorted_tasks[0].duration_seconds:.2f}s)")
```

---

## DevWorkflow å¹¶è¡Œæ¨¡å¼

### é˜¶æ®µä¾èµ–å…³ç³»

```python
STAGE_DEPENDENCIES = {
    WorkflowStage.REQUIREMENTS: [],
    WorkflowStage.FEATURE_DESIGN: [WorkflowStage.REQUIREMENTS],
    WorkflowStage.UX_DESIGN: [WorkflowStage.REQUIREMENTS],     # â† ä¸ FEATURE_DESIGN å¹¶è¡Œ
    WorkflowStage.DEV_PLAN: [WorkflowStage.FEATURE_DESIGN, WorkflowStage.UX_DESIGN],
    WorkflowStage.IMPLEMENTATION: [WorkflowStage.DEV_PLAN]
}
```

### æ‰§è¡Œæµç¨‹

```
REQUIREMENTS (Level 0)
    â†“
    â”œâ”€ FEATURE_DESIGN (Level 1) â”
    â””â”€ UX_DESIGN (Level 1)      â”œâ”€ å¹¶è¡Œæ‰§è¡Œ
                                â”˜
    â†“
DEV_PLAN (Level 2)
    â†“
IMPLEMENTATION (Level 3)
```

### ä½¿ç”¨ç¤ºä¾‹

```python
from orchestrator.skills.dev_workflow import DevWorkflowAgent

# å¹¶è¡Œæ¨¡å¼
agent = DevWorkflowAgent(
    enable_parallel=True,
    max_workers=2
)

result = agent.run("åˆ›å»ºç”µå•†å¹³å°", verbose=True)

# è¾“å‡ºç¤ºä¾‹ï¼š
# [å¹¶è¡Œæ¨¡å¼] å¯ç”¨ V3 å¹¶è¡Œæ‰§è¡Œ
# æœ€å¤§å¹¶è¡Œæ•°: 2
#
# [ä¾èµ–åˆ†æ] è¯†åˆ«å‡º 4 ä¸ªæ‰§è¡Œå±‚çº§ï¼š
#   Level 0: ['requirements']
#   Level 1: ['feature_design', 'ux_design']
#   Level 2: ['dev_plan']
#   Level 3: ['implementation']
#
# ============================================================
# æ‰§è¡Œ Level 1: 2 ä¸ªé˜¶æ®µ
# [å¹¶è¡Œ] ['feature_design', 'ux_design']
# ============================================================
#
# [feature_design]
#   åç«¯: claude
#   è€—æ—¶: 15.23s
#   [OK] éªŒè¯é€šè¿‡
#
# [ux_design]
#   åç«¯: gemini
#   è€—æ—¶: 14.87s
#   [OK] éªŒè¯é€šè¿‡
```

---

## é«˜çº§ç”¨æ³•

### è‡ªå®šä¹‰ä¾èµ–å…³ç³»

```python
from orchestrator.core.dependency_analyzer import Task

# å®šä¹‰è‡ªå®šä¹‰ä¾èµ–
tasks = [
    Task(
        namespace="skill:step1",
        request="æ­¥éª¤1",
        dependencies=[]  # æ— ä¾èµ–
    ),
    Task(
        namespace="skill:step2",
        request="æ­¥éª¤2",
        dependencies=["skill:step1"]  # ä¾èµ–æ­¥éª¤1
    ),
    Task(
        namespace="skill:step3",
        request="æ­¥éª¤3",
        dependencies=["skill:step1"]  # ä¹Ÿä¾èµ–æ­¥éª¤1ï¼ˆå¯ä¸æ­¥éª¤2å¹¶è¡Œï¼‰
    ),
]

# æ‰§è¡Œ
scheduler.execute_tasks(tasks, enable_dependency_analysis=True)
```

### åŠ¨æ€è°ƒæ•´å¹¶è¡Œåº¦

```python
# æ ¹æ®ç³»ç»Ÿè´Ÿè½½åŠ¨æ€è°ƒæ•´
import psutil

def get_optimal_workers():
    cpu_usage = psutil.cpu_percent()
    if cpu_usage > 80:
        return 2  # é«˜è´Ÿè½½ï¼Œå‡å°‘å¹¶è¡Œ
    elif cpu_usage > 50:
        return 3  # ä¸­è´Ÿè½½
    else:
        return 5  # ä½è´Ÿè½½ï¼Œå¢åŠ å¹¶è¡Œ

scheduler = ParallelScheduler(
    factory=factory,
    max_workers=get_optimal_workers()
)
```

### æ¡ä»¶å¹¶è¡Œ

```python
# åªåœ¨ç‰¹å®šæ¡ä»¶ä¸‹å¹¶è¡Œ
def should_parallel(requests):
    # å°‘äº3ä¸ªä»»åŠ¡ä¸å€¼å¾—å¹¶è¡Œ
    if len(requests) < 3:
        return False
    # ä»»åŠ¡ç±»å‹éƒ½æ˜¯ IO å¯†é›†ï¼Œé€‚åˆå¹¶è¡Œ
    return all("api" in req or "fetch" in req for req in requests)

enable_parallel = should_parallel(requests)
result = orch.process_batch(requests, enable_parallel=enable_parallel)
```

---

## æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: å¹¶è¡Œæœªç”Ÿæ•ˆ

**ç—‡çŠ¶**ï¼š`enable_parallel=True` ä½†ä»»åŠ¡ä»ä¸²è¡Œæ‰§è¡Œ

**è¯Šæ–­**ï¼š
```python
# æ£€æŸ¥ auto_discover æ˜¯å¦å¯ç”¨
print(orch.auto_discover)  # åº”ä¸º True

# æ£€æŸ¥ V3 ç»„ä»¶æ˜¯å¦å¯ç”¨
from orchestrator.core.parallel_scheduler import ParallelScheduler
print(ParallelScheduler is not None)  # åº”ä¸º True

# æ£€æŸ¥ä»»åŠ¡ä¾èµ–
analyzer = DependencyAnalyzer(orch.registry)
groups = analyzer.group_parallel_tasks(tasks)
for group in groups:
    print(f"Level {group.level}: {len(group.tasks)} tasks")
    # å¦‚æœæ¯ä¸ª Level åªæœ‰ 1 ä¸ªä»»åŠ¡ï¼Œè¯´æ˜å­˜åœ¨å¼ºä¾èµ–é“¾
```

### é—®é¢˜ 2: æ€§èƒ½æœªæå‡

**åŸå› åˆ†æ**ï¼š
1. ä»»åŠ¡é—´å­˜åœ¨ä¾èµ–é“¾ï¼ˆæ— æ³•å¹¶è¡Œï¼‰
2. ä»»åŠ¡æ•°é‡å°‘ï¼ˆå¹¶è¡Œå¼€é”€å¤§äºæ”¶ç›Šï¼‰
3. `max_workers` è®¾ç½®è¿‡å°

**è§£å†³**ï¼š
```python
# 1. æ£€æŸ¥ä¾èµ–å…³ç³»
stats = analyzer.get_stats(tasks)
print(f"ç‹¬ç«‹ä»»åŠ¡: {stats['independent_tasks']}/{stats['total_tasks']}")

# 2. å¢åŠ  max_workers
scheduler = ParallelScheduler(factory=factory, max_workers=5)  # å¢åŠ åˆ°5

# 3. æ‰¹é‡å¤„ç†
if len(requests) < 5:
    # å°‘é‡ä»»åŠ¡ï¼Œä¸²è¡Œæ›´å¿«
    result = orch.process_batch(requests, enable_parallel=False)
```

### é—®é¢˜ 3: è¶…æ—¶é”™è¯¯

**ç—‡çŠ¶**ï¼š`Task timeout after 120s`

**è§£å†³**ï¼š
```python
# å¢åŠ è¶…æ—¶æ—¶é—´
scheduler = ParallelScheduler(
    factory=factory,
    max_workers=3,
    timeout_per_task=300  # å¢åŠ åˆ°5åˆ†é’Ÿ
)

# æˆ–é’ˆå¯¹ç‰¹å®šä»»åŠ¡è°ƒæ•´
orch = MasterOrchestrator(
    enable_parallel=True,
    parallel_timeout=300  # å…¨å±€è¶…æ—¶è®¾ç½®
)
```

---

## æ€§èƒ½åŸºå‡†

### æµ‹è¯•åœºæ™¯

**åœºæ™¯ 1**: 5 ä¸ªç‹¬ç«‹ API è°ƒç”¨ä»»åŠ¡

| æ¨¡å¼ | è€—æ—¶ | åŠ é€Ÿæ¯” |
|------|------|--------|
| ä¸²è¡Œ | 50s | 1.0x |
| å¹¶è¡Œ (workers=3) | 20s | 2.5x |
| å¹¶è¡Œ (workers=5) | 12s | 4.2x |

**åœºæ™¯ 2**: DevWorkflow 5 é˜¶æ®µ

| æ¨¡å¼ | è€—æ—¶ | åŠ é€Ÿæ¯” |
|------|------|--------|
| ä¸²è¡Œ | 90s | 1.0x |
| å¹¶è¡Œ (workers=2) | 60s | 1.5x |

**åœºæ™¯ 3**: 10 ä¸ª CPU å¯†é›†ä»»åŠ¡ï¼ˆ4æ ¸CPUï¼‰

| æ¨¡å¼ | è€—æ—¶ | åŠ é€Ÿæ¯” |
|------|------|--------|
| ä¸²è¡Œ | 100s | 1.0x |
| å¹¶è¡Œ (workers=4) | 30s | 3.3x |
| å¹¶è¡Œ (workers=8) | 28s | 3.6x (è¾¹é™…é€’å‡) |

---

## æœ€ä½³å®è·µ

### 1. ä½•æ—¶ä½¿ç”¨å¹¶è¡Œ

âœ… **é€‚åˆå¹¶è¡Œ**ï¼š
- å¤šä¸ªç‹¬ç«‹çš„ API è°ƒç”¨
- æ‰¹é‡æ–‡ä»¶å¤„ç†
- å¤šä¸ªç‹¬ç«‹çš„ä»£ç åˆ†æä»»åŠ¡
- DevWorkflow çš„ FEATURE_DESIGN + UX_DESIGN

âŒ **ä¸é€‚åˆå¹¶è¡Œ**ï¼š
- ä»»åŠ¡é—´æœ‰å¼ºä¾èµ–å…³ç³»
- å•ä¸ªä»»åŠ¡ï¼ˆå¹¶è¡Œå¼€é”€å¤§äºæ”¶ç›Šï¼‰
- CPU å¯†é›† + workers è¶…è¿‡ CPU æ ¸å¿ƒæ•°
- æœ‰ä¸¥æ ¼é¡ºåºè¦æ±‚çš„ä»»åŠ¡

### 2. max_workers è®¾ç½®

```python
import os

# CPU å¯†é›†ä»»åŠ¡
max_workers = os.cpu_count()

# IO å¯†é›†ä»»åŠ¡ï¼ˆå¦‚ API è°ƒç”¨ï¼‰
max_workers = os.cpu_count() * 2

# é™åˆ¶ä¸Šé™ï¼ˆé¿å…è¿‡åº¦å¹¶è¡Œï¼‰
max_workers = min(max_workers, 10)

# è€ƒè™‘é€Ÿç‡é™åˆ¶
# å¦‚æœ API é™åˆ¶ 5 req/sï¼Œè®¾ç½® max_workers=5
```

### 3. é”™è¯¯å¤„ç†

```python
# å¯ç”¨è¯¦ç»†æ—¥å¿—
result = orch.process_batch(requests, enable_parallel=True, verbose=True)

# æ£€æŸ¥å¤±è´¥ä»»åŠ¡
if result.failed > 0:
    print(f"å¤±è´¥ä»»åŠ¡æ•°: {result.failed}")
    for task_result in result.task_results:
        if not task_result.success:
            print(f"  {task_result.namespace}: {task_result.error}")

# å¤±è´¥å¿«é€Ÿç­–ç•¥
scheduler = ParallelScheduler(
    factory=factory,
    max_workers=3,
    fail_fast=True  # ç¬¬ä¸€ä¸ªå¤±è´¥æ—¶ç»ˆæ­¢
)
```

### 4. èµ„æºç®¡ç†

```python
# ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨
with MasterOrchestrator(
    auto_discover=True,
    enable_parallel=True
) as orch:
    result = orch.process_batch(requests)
    # è‡ªåŠ¨æ¸…ç†èµ„æº
```

---

## API å‚è€ƒ

### MasterOrchestrator

```python
def process_batch(
    self,
    requests: List[str],
    enable_parallel: Optional[bool] = None,
    verbose: bool = False
) -> BatchResult:
    """æ‰¹é‡å¤„ç†è¯·æ±‚ï¼ˆæ”¯æŒå¹¶è¡Œï¼‰"""
    pass
```

### ParallelScheduler

```python
class ParallelScheduler:
    def __init__(
        self,
        factory: ExecutorFactory,
        max_workers: int = 3,
        timeout_per_task: int = 120,
        fail_fast: bool = False
    ):
        pass

    def execute_parallel_groups(
        self,
        groups: List[ParallelGroup],
        fail_fast: Optional[bool] = None
    ) -> BatchResult:
        """æ‰§è¡Œå¹¶è¡Œç»„"""
        pass

    def execute_tasks(
        self,
        tasks: List[Task],
        enable_dependency_analysis: bool = True
    ) -> BatchResult:
        """æ‰§è¡Œä»»åŠ¡åˆ—è¡¨"""
        pass
```

### DependencyAnalyzer

```python
class DependencyAnalyzer:
    def group_parallel_tasks(self, tasks: List[Task]) -> List[ParallelGroup]:
        """åˆ†ç»„å¹¶è¡Œä»»åŠ¡"""
        pass

    def topological_sort(self, graph: Dict[str, Set[str]]) -> List[List[str]]:
        """æ‹“æ‰‘æ’åº"""
        pass

    def detect_cycles(self, graph: Dict[str, Set[str]]) -> List[List[str]]:
        """æ£€æµ‹å¾ªç¯ä¾èµ–"""
        pass
```

---

## ç›¸å…³æ–‡æ¡£

- [è‡ªåŠ¨å‘ç°æ–‡æ¡£](./AUTO_DISCOVERY.md)
- [æ¶æ„æ–‡æ¡£](./ARCHITECTURE.md)
- [é…ç½®æ¨¡æ¿](../orchestrator.yaml)

---

**æœ€åæ›´æ–°**: 2026-01-04
**ç‰ˆæœ¬**: 3.0.0
